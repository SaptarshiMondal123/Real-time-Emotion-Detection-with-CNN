{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":234911,"sourceType":"datasetVersion","datasetId":99505}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Libraries and Setting Up the Environment","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\n\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\nfrom keras.models import Model,Sequential","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"pic_size=48\nfolder_path=\"/kaggle/input/face-expression-recognition-dataset/images/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"expr='disgust'\nplt.figure(figsize= (12,12))\nfor i in range(1, 10, 1):\n    plt.subplot(3,3,i)\n    img = load_img(folder_path+\"train/\"+expr+\"/\"+os.listdir(folder_path+\"train/\"+expr)[i],target_size=(pic_size,pic_size))\n    plt.imshow(img)   \nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"batch_size=128\ndata_train = ImageDataGenerator(\n    rescale = 1.0/255.0,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    rotation_range = 20,\n    horizontal_flip = True\n)\n\ndata_val = ImageDataGenerator(rescale=1.0/255)\n\ntrain_set = data_train.flow_from_directory(\n    folder_path + \"train\", \n    target_size=(56, 56), \n    color_mode='grayscale', \n    batch_size=batch_size, \n    class_mode='categorical', \n    shuffle=True\n)\n\ntest_set = data_val.flow_from_directory(\n    folder_path + \"validation\", \n    target_size=(56, 56), \n    color_mode='grayscale', \n    batch_size=batch_size, \n    class_mode='categorical', \n    shuffle=False\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building The Model","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\nfrom keras.models import Model, Sequential\n\nno_of_class = 7\nmodel = Sequential()\n\n# 1st CNN Layer\nmodel.add(Conv2D(64, (3, 3), padding='same', input_shape=(56, 56, 1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 2nd CNN Layer\nmodel.add(Conv2D(128, (5, 5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 3rd CNN Layer\nmodel.add(Conv2D(512, (3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 4th CNN Layer\nmodel.add(Conv2D(512, (3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n# Fully connected layer 1\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_class, activation='softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compiling the Model","metadata":{}},{"cell_type":"code","source":"opt = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting Up Callbacks","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\n# Corrected checkpoint definition\ncheckpoint = ModelCheckpoint(\"/kaggle/working/model.keras\", \n                             monitor='val_accuracy', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='max')\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                                patience=3,\n                                verbose=1, \n                                restore_best_weights=True)\n\nreduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n                                        factor=0.2,\n                                        patience=3,\n                                        verbose=1,\n                                        min_delta=0.0001)\n\ncallbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n\nepochs = 50\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(learning_rate=0.001),\n              metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Training the Model","metadata":{}},{"cell_type":"code","source":"history = model.fit(train_set,\n                    steps_per_epoch=train_set.n // train_set.batch_size,\n                    epochs=epochs,\n                    validation_data=test_set,\n                    validation_steps=test_set.n // test_set.batch_size,\n                    callbacks=callbacks_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy And Loss Plotting","metadata":{}},{"cell_type":"code","source":"plt.style.use('dark_background')\n\nplt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}